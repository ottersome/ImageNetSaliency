# Intro

Same paper as before, different day

# Still Chapter 1

Under the Probabilistic Formulation Context our goal is to minimize the difference between the target joint distribution 
$Q_{x,y}$ and the *learned* joined distribution $P_{x,y}(\bold{w})$

* The aforementioned distribution difstances can be measure din terms of the **Kullback-Leibler(KL)** divergence.
* Alternataively,we can also learn the conditional distribution $P_{y|x}(\bold{w})$. Meaning
the probability of y  given x on model. 
    * Under this formulation we can can get an equivalent model to standard loss with 
    **log-likelihood** of the probability density function* 
* The **Bayesian FOrmulation** is the one that is useful to understand the 
variational pruning approaches presented in the alter sections. a

Bayesian Inference
:   $p(\bold{w}|S) = p(S|\bold{w})p(\bold{w})/p(S)$. i.e. turning the prior distribution 
to a *posterior distribution*. However computing the *posterior distribution* is not
often possible in practice, as it requires computing the *marginal likelihood*
which is an intractable integral for most complex models. **Thus approximation 
enters the picture**.

**Variational Inference** enters the sage. Here, the posterior distribution
$p(\bold{w}|s)$ is approximated by a parametric distibution  $q_{\delta}(\bold{w})$.

    * We still use the KL divergence for measuring quality of approximation 

* Theres a lot of talk of using Bayes for Deep Learning, but a major conclusion
to draw here is that **Variational Dropout can effectively sparsify
DNNs**(more on section 3.7)

##  Convolutional Layers as Designed Sparsity

The convolution operator itself and its variants can be seen as a sparse version of fully connected layers. 

# Overview of Sparsity in Deep Learning

The Utility of Sparsification lies in two very different areas :
1. Improved generalization and robustness
2. Improved performance for inference and/or training.

## Generalization

* **Occam's hill** is a curve that shows the typical test error -vs  sparsity.
Shows that sparsity can help with generalization(to some point) then it stays stabel to finally 
meet a steep drop of accuracy.

## Perforamnce and Model Storage

IT talks a lot about encoding and just  stuff that doesn't
matter to my research at the 
moment. You can reference it if you want 

## What can be sparsified?

There can be two types of sparsification that we can distinguishg:

1. Model Sparsification: This changes the model can be considered as a generaalization of 
Neural Architecture Search(NAS). Model sparsification changes the model but does not change the sparsity 
pattern across multiple inference or forward passes. (Weights and neurons can be sparsified). Weights
in filters may be removed as well. *Structued weight sparsification* has been developed to reduce
indexing overheads and improve efficiency of execution.
2. Ephermeral Sparsificaiton: This is applied during the calculation of each example individually and -
is only relevant for this example. **We can apply sparsification to the mask that will perform 
backwards propagation**, this approach can lead to sifnificant performance improvements(especially in distributed settings).

* *More model sparsification material on sections 3 and 48

* Another option for sparsification is to wait for individual  gradients to reach a certain threshold 
before applying.(This is still an ephemeral approach).

# Reading an Introduction to Varational Autoencoders by Kingma and Welling


[Link Here](https://arxiv.org/pdf/1906.02691.pdf)

* 10:53 PM: So basically so far they talk a lot about why most of the processes in the real
wworld are generative models. This is because they can help to ask more general quiestions
and understand the causal relations of the world
* But in order to turn a *generative* model into  *discriminator* model we neeeed to use 
**Baye's rule**. (This can be often computationally expensive though)
* One can argue that an image is generated in the world by first identifying the object,
then generating the object in  3D and the projecting it onto a pixel grid.

    * A discriminative model takes these pixels values 
* It can be beneficial to study the data generating process as a way to guide the training 
of the discriminator, such as a classifier.
* **Variational Autoencoder** is a method used for *unsupervised representation learning*.
    * One may view VAE as an implicit form of *regularization*
* VAE can be viewed as two couple, but independently parameterized models:




